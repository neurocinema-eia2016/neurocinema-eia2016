<!DOCTYPE html>
<html >
<head>
    <meta charset="UTF-8">
    <title>An emotion-based video player</title>
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="css/emoticon.css">
    <link rel="stylesheet" href="css/content.css">
    <link type="text/css" rel="stylesheet" href="css/video-js.min.css" />
    <link href="//vjs.zencdn.net/5.8/video-js.min.css" rel="stylesheet">
    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <!-- Custom CSS -->
    <link href="css/logo-nav.css" rel="stylesheet">
    <link href="css/content.css" rel="stylesheet">
    <link type="text/css" rel="stylesheet" href="https://vjs.zencdn.net/4.12/video-js.css" />
    <script>
        // getUserMedia only works over https in Chrome 47+, so we redirect to https. Also notify user if running from file.
        if (window.location.protocol == "file:") {
            alert("You seem to be running this example directly from a file. Note that these examples only work when served from a server or localhost due to canvas cross-domain restrictions.");
        } else if (window.location.hostname !== "localhost" && window.location.protocol !== "https:"){
            window.location.protocol = "https";
        }
    </script>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Bootstrap Core JavaScript -->
    <script src="js/jquery/dist/jquery.js"></script>
    <script src="js/bootstrap.min.js"></script>
</head>
<body>
    <link href="css/default.css" rel="stylesheet">
    <script src="https://www.youtube.com/iframe_api"></script>
    <script src="js/jquery/dist/jquery.js"></script>
    <script src="js/jquery-ui/jquery-ui.min.js"></script>        
    <script src="js/raphael/raphael.js"></script>
    <!-- style-player -->        
    <link href="css/amalia.js.min.css" rel="stylesheet">
    <!-- /style-player -->        
    <!-- script-player -->        
    <script src="js/amalia.js/amalia.js.min.js"></script>
    <script src="js/amalia.js/amalia.js-plugin-timeline.min.js"></script>
    <script type="text/javascript" src="js/amalia.js-yt-player.min.js"></script>

    <script src="js/utils.js"></script>
    <script src="js/clmtrackr/clm.js"></script>
    <script src="js/clmtrackr/clmtrackr.js"></script>
    <script src="js/models/model_pca_20_svm_emotionDetection.js"></script>
    <script src="js/clmtrackr/Stats.js"></script>
    <script src="js/models/d3.min.js"></script>
    <script src="js/models/emotion_classifier.js"></script>
    <script src="js/models/emotionmodel.js"></script>

    <script src="https://www.gstatic.com/firebasejs/3.1.0/firebase.js"></script>

    <div id="player"></div>
    <div id="emotion_container">
        <div id="emotion_icons">
            <img class="emotion_icon" id="icon1" src="media/icons/angry.png">
            <img class="emotion_icon" id="icon2" src="media/icons/sad.png">
            <img class="emotion_icon" id="icon3" src="media/icons/surprised.png">
            <img class="emotion_icon" id="icon4" src="media/icons/happy.png">
        </div>
        <div id='emotion_chart'></div>
    </div>
    <video id="videoel" width="400" height="300" preload="auto" loop></video>
    
    <script>    
        // Initialize Amalia.js Player
        var player = null;
        var curtime = null
        // 2. Function to execute when the DOM is fully loaded
        $(document).ready(function () {
            // 3. Init player with default parameters
            $("#player").mediaPlayer({
                src: "media/Beetlejuice french scene - YouTube_360p.mp4",
                callbacks: {
                    onReady: 'onReady'
                }
            });
        });

        // 4. The API will call this function when the video player is ready.
        function onReady() {
            player = $('#player').data('fr.ina.amalia.player').getPlayer();
            // Set event listener on time change.
            $('#player').on('fr.ina.amalia.player.PlayerEventType.TIME_CHANGE', onTimeChange);
        }

        // 5. Function will call on click to button play
        function playVideo() {
            if (player !== null) {
                player.play();
            }
        }

        // Initialize Firebase
        var config = {
            apiKey: "AIzaSyBI1lAq_sWUkSyuw6_q9Tp4Xq57pTqQLUU",
            authDomain: "neurocinema-a859d.firebaseapp.com",
            databaseURL: "https://neurocinema-a859d.firebaseio.com",
            storageBucket: "neurocinema-a859d.appspot.com",
        };
        firebase.initializeApp(config);

        var vid = document.getElementById('videoel');
        // document.getElementById('youtube_player').style.visibility = 'hidden';

        /********** check and set up video/webcam **********/
        function enablestart() {
            var startbutton = document.getElementById('startbutton');
            startbutton.value = "start";
            startbutton.disabled = null;
            var showbutton = document.getElementById('showplayer');
            showbutton.disabled = null;
        }

        navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;
        window.URL = window.URL || window.webkitURL || window.msURL || window.mozURL;

        // check for camerasupport
        if (navigator.getUserMedia) {
            // set up stream
            var videoSelector = {video : true};
            if (window.navigator.appVersion.match(/Chrome\/(.*?) /)) {
                var chromeVersion = parseInt(window.navigator.appVersion.match(/Chrome\/(\d+)\./)[1], 10);
                if (chromeVersion < 20) {
                    videoSelector = "video";
                }
            };
        
            navigator.getUserMedia(videoSelector, function( stream ) {
                if (vid.mozCaptureStream) {
                    vid.mozSrcObject = stream;
                } else {
                    vid.src = (window.URL && window.URL.createObjectURL(stream)) || stream;
                }
                vid.play();
            }, function() {
                //insertAltVideo(vid);
                alert("There was some problem trying to fetch video from your webcam. If you have a webcam, please make sure to accept when the browser asks for access to your webcam.");
            });
        } else {
            //insertAltVideo(vid);
            alert("This demo depends on getUserMedia, which your browser does not seem to support. :(");
        }

        // guess the viewer id from cookies
        var viewer_id = getCookie("viwer_id");
        if (viewer_id == "") {
            var nb_view = 1;
            var today = new Date().toISOString();
            setCookie("viwer_id", today, 30);
            setCookie("nb_view", 1, 30);
        } else {
            // count number of views
            var nb_view = getCookie("nb_view");
            console.log(nb_view)
            setCookie("nb_view", parseInt(nb_view) + 1, 30);
        }

        var day = parseInt(viewer_id.replaceAll('-','').split('T')[0])
        var data = 'emotions'
        var path = data + '/' + viewer_id.replaceAll(':','')
        path = path.replaceAll('-','').replace('.','')
        /*********** setup of emotion detection *************/
        var last = ""; //["", "", "", ""];
        var timestamp = ""; //["", "", "", ""];
        var enames = ['angry/' + String(nb_view).pad(3), 
                      'sad/' + String(nb_view).pad(3), 
                      'surprised/' + String(nb_view).pad(3), 
                      'happy/' + String(nb_view).pad(3)]
        var ctrack = new clm.tracker({useWebGL : true});
        ctrack.init(pModel);

        for (var i = 0;i < enames.length; i++) {
            // init firebase
            firebase.database().ref(path + '/' + enames[i]).set({
                localisation: [{
                    sublocalisations: {
                        localisation: [],
                    },
                    type: "segments",
                    tcin: "00:00:00.0000",
                    tcout: "00:60:00.0000",
                    tclevel: 0
                }],
                id: enames[i],
                type: "segments",
                algorithm: "clmtrackr",
                processor: "R. Trachel",
                processed: day,
                version: 1
            });
        }

        function writeEmotionSegment(videoID, min, sec, ms) {
            if (last == "") {
                last = videoID
            }
            if (timestamp == "") {
                console.log('getting: ' + timestamp)
                timestamp = "00:".concat(min).concat(":").concat(sec).concat(".").concat(ms)
            } else {
                if (last == videoID) {
                    // remember only the first time stamp
                    console.log('not saving timestamp...')
                } else {
                    newtime = "00:".concat(min).concat(":").concat(sec).concat(".").concat(ms)
                    var ref = firebase.database().ref(path + '/' + videoID + '/localisation/0/sublocalisations/localisation');
                    // sync down from server
                    var list = [];
                    ref.on('value', function(snap) { list = snap.val(); });
                    // this is the correct way to change an array
                    list.push({
                        tcin: timestamp,
                        tcout: newtime,
                        tclevel: 1
                    });
                    ref.set(list);
                    console.log('writting: ' + newtime)
                    timestamp = "";
                    last = "";
                }
            }
        }

        function detectEmotionLoop() {
            requestAnimFrame(detectEmotionLoop);
            var cp = ctrack.getCurrentParameters();
            var er = ec.meanPredict(cp);
            if (player !== null) {
                curtime = player.getCurrentTime();
            } else {
                curtime = 0;
            }
            if (er) {
                console.log(enames[0] + ': ' + er[0].value)
                for (var i = 0;i < er.length;i++) {
                    if (er[i].value > 0.8) {
                        // console.log(enames[i] + ': ' + er[i].value)
                        var minnow = String(curtime / 60).split('.')[0].pad(2);
                        var secnow = String(curtime).split('.')[0].pad(2);
                        var msnow = String(String(curtime).split('.')[1]).substr(0,4)
                        writeEmotionSegment(enames[i], minnow, secnow, msnow);
                    }
                }
            }
        }
        
        var ec = new emotionClassifier();
        ec.init(emotionModel);
        var emotionData = ec.getBlank();    
        
        ctrack.start(vid);
        // start loop to draw face
        detectEmotionLoop();
        
        </script>
    </body>
</html>
